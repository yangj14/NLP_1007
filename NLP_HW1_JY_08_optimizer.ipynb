{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import random\n",
    "import string\n",
    "from nltk import ngrams\n",
    "\n",
    "#Load data\n",
    "#Tokenization\n",
    "#Change method: load data as list of lower case words, remove symbols including '<br />'\n",
    "\n",
    "def folder_file(path, label):\n",
    "    filelist = os.listdir(path)\n",
    "    review = []\n",
    "    target = []\n",
    "    for i in filelist:\n",
    "        file = os.path.join(path,i)\n",
    "        f = open(file).read()\n",
    "        f_rev = f.replace('<br />', ' ')\n",
    "        lines = f_rev.split(' ')\n",
    "        symbols = '!?${}()[].,:;+-*/&|<>=~\" '\n",
    "        words = map(lambda Element: Element.translate(str.maketrans(\"\",\"\",symbols)).strip().lower(), lines)\n",
    "        words = list(filter(None, words))\n",
    "        review.append(words)\n",
    "        target.append(label)\n",
    "    return review, target\n",
    "\n",
    "train_pos_path = \"aclImdb/train/pos\"\n",
    "train_neg_path = \"aclImdb/train/neg\"\n",
    "test_pos_path = \"aclImdb/test/pos\"\n",
    "test_neg_path = \"aclImdb/test/neg\"\n",
    "\n",
    "review_train_pos, target_train_pos = folder_file(train_pos_path, 1)\n",
    "review_train_neg, target_train_neg = folder_file(train_neg_path, 0)\n",
    "review_test_pos, target_test_pos = folder_file(test_pos_path, 1)\n",
    "review_test_neg, target_test_neg = folder_file(test_neg_path, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Test dataset size is 25000\n"
     ]
    }
   ],
   "source": [
    "# Split train data into actual train and validation sets, make a list to store all training tokens\n",
    "\n",
    "train_split = 10000\n",
    "\n",
    "train_data_pos = review_train_pos[:train_split]\n",
    "train_targets_pos = target_train_pos[:train_split]\n",
    "\n",
    "train_data_neg = review_train_neg[:train_split]\n",
    "train_targets_neg = target_train_neg[:train_split]\n",
    "\n",
    "val_data_pos = review_train_pos[train_split:]\n",
    "val_targets_pos = target_train_pos[train_split:]\n",
    "\n",
    "val_data_neg = review_train_neg[train_split:]\n",
    "val_targets_neg = target_train_neg[train_split:]\n",
    "\n",
    "#Define train, val, test datasets\n",
    "\n",
    "train_data_tokens_ori = train_data_pos + train_data_neg\n",
    "train_target = train_targets_pos + train_targets_neg\n",
    "\n",
    "val_data_tokens_ori = val_data_pos + val_data_neg\n",
    "val_target = val_targets_pos + val_targets_neg\n",
    "\n",
    "test_data_tokens_ori = review_test_neg + review_test_pos\n",
    "test_target = target_test_neg + target_test_pos\n",
    "\n",
    "print (\"Train dataset size is {}\".format(len(train_data_tokens_ori)))\n",
    "print (\"Val dataset size is {}\".format(len(val_data_tokens_ori)))\n",
    "print (\"Test dataset size is {}\".format(len(test_data_tokens_ori)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add n gram to train data tokens\n",
    "\n",
    "# Define ngrams\n",
    "def find_ngrams(input_list, n):\n",
    "    return zip(*[input_list[i:] for i in range(n)])\n",
    "\n",
    "# Add ngram to tokens\n",
    "def add_ngram(tokens_ori, n):\n",
    "    tokens = []\n",
    "    for i in range(len(tokens_ori)):\n",
    "        n_grams = find_ngrams(tokens_ori[i], n)\n",
    "        a = tokens_ori[i] + list(n_grams)\n",
    "        tokens.append(a)\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.114147015003255\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "start = timeit.default_timer()\n",
    "\n",
    "train_data_tokens_1 = add_ngram(train_data_tokens_ori, 2)\n",
    "val_data_tokens_1 = add_ngram(val_data_tokens_ori, 2)\n",
    "test_data_tokens_1 = add_ngram(test_data_tokens_ori, 2)\n",
    "\n",
    "train_data_tokens = add_ngram(train_data_tokens_1, 3)\n",
    "val_data_tokens = add_ngram(val_data_tokens_1, 3)\n",
    "test_data_tokens = add_ngram(test_data_tokens_1, 3)\n",
    "    \n",
    "stop = timeit.default_timer() \n",
    "print (stop - start)\n",
    "\n",
    "\n",
    "# from train_data_tokens, join elements in all lists\n",
    "import itertools\n",
    "all_train_tokens = list(itertools.chain.from_iterable(train_data_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['i',\n",
       "  'saw',\n",
       "  'the',\n",
       "  'movie',\n",
       "  'with',\n",
       "  'two',\n",
       "  'grown',\n",
       "  'children',\n",
       "  'although',\n",
       "  'it',\n",
       "  'was',\n",
       "  'not',\n",
       "  'as',\n",
       "  'clever',\n",
       "  'as',\n",
       "  'shrek',\n",
       "  'i',\n",
       "  'thought',\n",
       "  'it',\n",
       "  'was',\n",
       "  'rather',\n",
       "  'good',\n",
       "  'in',\n",
       "  'a',\n",
       "  'movie',\n",
       "  'theatre',\n",
       "  'surrounded',\n",
       "  'by',\n",
       "  'children',\n",
       "  'who',\n",
       "  'were',\n",
       "  'on',\n",
       "  'spring',\n",
       "  'break',\n",
       "  'there',\n",
       "  'was',\n",
       "  'not',\n",
       "  'a',\n",
       "  'sound',\n",
       "  'so',\n",
       "  'i',\n",
       "  'know',\n",
       "  'the',\n",
       "  'children',\n",
       "  'all',\n",
       "  'liked',\n",
       "  'it',\n",
       "  'there',\n",
       "  'parents',\n",
       "  'also',\n",
       "  'seemed',\n",
       "  'engaged',\n",
       "  'the',\n",
       "  'death',\n",
       "  'and',\n",
       "  'apparent',\n",
       "  'death',\n",
       "  'of',\n",
       "  'characters',\n",
       "  'brought',\n",
       "  'about',\n",
       "  'the',\n",
       "  'appropriate',\n",
       "  'gasps',\n",
       "  'and',\n",
       "  'comments',\n",
       "  'hopefully',\n",
       "  'people',\n",
       "  'realize',\n",
       "  'this',\n",
       "  'movie',\n",
       "  'was',\n",
       "  'made',\n",
       "  'for',\n",
       "  'kids',\n",
       "  'as',\n",
       "  'such',\n",
       "  'it',\n",
       "  'was',\n",
       "  'successful',\n",
       "  'although',\n",
       "  'i',\n",
       "  'liked',\n",
       "  'it',\n",
       "  'too',\n",
       "  'personally',\n",
       "  'i',\n",
       "  'liked',\n",
       "  'the',\n",
       "  'scrat',\n",
       "  ('i', 'saw'),\n",
       "  ('saw', 'the'),\n",
       "  ('the', 'movie'),\n",
       "  ('movie', 'with'),\n",
       "  ('with', 'two'),\n",
       "  ('two', 'grown'),\n",
       "  ('grown', 'children'),\n",
       "  ('children', 'although'),\n",
       "  ('although', 'it'),\n",
       "  ('it', 'was'),\n",
       "  ('was', 'not'),\n",
       "  ('not', 'as'),\n",
       "  ('as', 'clever'),\n",
       "  ('clever', 'as'),\n",
       "  ('as', 'shrek'),\n",
       "  ('shrek', 'i'),\n",
       "  ('i', 'thought'),\n",
       "  ('thought', 'it'),\n",
       "  ('it', 'was'),\n",
       "  ('was', 'rather'),\n",
       "  ('rather', 'good'),\n",
       "  ('good', 'in'),\n",
       "  ('in', 'a'),\n",
       "  ('a', 'movie'),\n",
       "  ('movie', 'theatre'),\n",
       "  ('theatre', 'surrounded'),\n",
       "  ('surrounded', 'by'),\n",
       "  ('by', 'children'),\n",
       "  ('children', 'who'),\n",
       "  ('who', 'were'),\n",
       "  ('were', 'on'),\n",
       "  ('on', 'spring'),\n",
       "  ('spring', 'break'),\n",
       "  ('break', 'there'),\n",
       "  ('there', 'was'),\n",
       "  ('was', 'not'),\n",
       "  ('not', 'a'),\n",
       "  ('a', 'sound'),\n",
       "  ('sound', 'so'),\n",
       "  ('so', 'i'),\n",
       "  ('i', 'know'),\n",
       "  ('know', 'the'),\n",
       "  ('the', 'children'),\n",
       "  ('children', 'all'),\n",
       "  ('all', 'liked'),\n",
       "  ('liked', 'it'),\n",
       "  ('it', 'there'),\n",
       "  ('there', 'parents'),\n",
       "  ('parents', 'also'),\n",
       "  ('also', 'seemed'),\n",
       "  ('seemed', 'engaged'),\n",
       "  ('engaged', 'the'),\n",
       "  ('the', 'death'),\n",
       "  ('death', 'and'),\n",
       "  ('and', 'apparent'),\n",
       "  ('apparent', 'death'),\n",
       "  ('death', 'of'),\n",
       "  ('of', 'characters'),\n",
       "  ('characters', 'brought'),\n",
       "  ('brought', 'about'),\n",
       "  ('about', 'the'),\n",
       "  ('the', 'appropriate'),\n",
       "  ('appropriate', 'gasps'),\n",
       "  ('gasps', 'and'),\n",
       "  ('and', 'comments'),\n",
       "  ('comments', 'hopefully'),\n",
       "  ('hopefully', 'people'),\n",
       "  ('people', 'realize'),\n",
       "  ('realize', 'this'),\n",
       "  ('this', 'movie'),\n",
       "  ('movie', 'was'),\n",
       "  ('was', 'made'),\n",
       "  ('made', 'for'),\n",
       "  ('for', 'kids'),\n",
       "  ('kids', 'as'),\n",
       "  ('as', 'such'),\n",
       "  ('such', 'it'),\n",
       "  ('it', 'was'),\n",
       "  ('was', 'successful'),\n",
       "  ('successful', 'although'),\n",
       "  ('although', 'i'),\n",
       "  ('i', 'liked'),\n",
       "  ('liked', 'it'),\n",
       "  ('it', 'too'),\n",
       "  ('too', 'personally'),\n",
       "  ('personally', 'i'),\n",
       "  ('i', 'liked'),\n",
       "  ('liked', 'the'),\n",
       "  ('the', 'scrat'),\n",
       "  ('i', 'saw', 'the'),\n",
       "  ('saw', 'the', 'movie'),\n",
       "  ('the', 'movie', 'with'),\n",
       "  ('movie', 'with', 'two'),\n",
       "  ('with', 'two', 'grown'),\n",
       "  ('two', 'grown', 'children'),\n",
       "  ('grown', 'children', 'although'),\n",
       "  ('children', 'although', 'it'),\n",
       "  ('although', 'it', 'was'),\n",
       "  ('it', 'was', 'not'),\n",
       "  ('was', 'not', 'as'),\n",
       "  ('not', 'as', 'clever'),\n",
       "  ('as', 'clever', 'as'),\n",
       "  ('clever', 'as', 'shrek'),\n",
       "  ('as', 'shrek', 'i'),\n",
       "  ('shrek', 'i', 'thought'),\n",
       "  ('i', 'thought', 'it'),\n",
       "  ('thought', 'it', 'was'),\n",
       "  ('it', 'was', 'rather'),\n",
       "  ('was', 'rather', 'good'),\n",
       "  ('rather', 'good', 'in'),\n",
       "  ('good', 'in', 'a'),\n",
       "  ('in', 'a', 'movie'),\n",
       "  ('a', 'movie', 'theatre'),\n",
       "  ('movie', 'theatre', 'surrounded'),\n",
       "  ('theatre', 'surrounded', 'by'),\n",
       "  ('surrounded', 'by', 'children'),\n",
       "  ('by', 'children', 'who'),\n",
       "  ('children', 'who', 'were'),\n",
       "  ('who', 'were', 'on'),\n",
       "  ('were', 'on', 'spring'),\n",
       "  ('on', 'spring', 'break'),\n",
       "  ('spring', 'break', 'there'),\n",
       "  ('break', 'there', 'was'),\n",
       "  ('there', 'was', 'not'),\n",
       "  ('was', 'not', 'a'),\n",
       "  ('not', 'a', 'sound'),\n",
       "  ('a', 'sound', 'so'),\n",
       "  ('sound', 'so', 'i'),\n",
       "  ('so', 'i', 'know'),\n",
       "  ('i', 'know', 'the'),\n",
       "  ('know', 'the', 'children'),\n",
       "  ('the', 'children', 'all'),\n",
       "  ('children', 'all', 'liked'),\n",
       "  ('all', 'liked', 'it'),\n",
       "  ('liked', 'it', 'there'),\n",
       "  ('it', 'there', 'parents'),\n",
       "  ('there', 'parents', 'also'),\n",
       "  ('parents', 'also', 'seemed'),\n",
       "  ('also', 'seemed', 'engaged'),\n",
       "  ('seemed', 'engaged', 'the'),\n",
       "  ('engaged', 'the', 'death'),\n",
       "  ('the', 'death', 'and'),\n",
       "  ('death', 'and', 'apparent'),\n",
       "  ('and', 'apparent', 'death'),\n",
       "  ('apparent', 'death', 'of'),\n",
       "  ('death', 'of', 'characters'),\n",
       "  ('of', 'characters', 'brought'),\n",
       "  ('characters', 'brought', 'about'),\n",
       "  ('brought', 'about', 'the'),\n",
       "  ('about', 'the', 'appropriate'),\n",
       "  ('the', 'appropriate', 'gasps'),\n",
       "  ('appropriate', 'gasps', 'and'),\n",
       "  ('gasps', 'and', 'comments'),\n",
       "  ('and', 'comments', 'hopefully'),\n",
       "  ('comments', 'hopefully', 'people'),\n",
       "  ('hopefully', 'people', 'realize'),\n",
       "  ('people', 'realize', 'this'),\n",
       "  ('realize', 'this', 'movie'),\n",
       "  ('this', 'movie', 'was'),\n",
       "  ('movie', 'was', 'made'),\n",
       "  ('was', 'made', 'for'),\n",
       "  ('made', 'for', 'kids'),\n",
       "  ('for', 'kids', 'as'),\n",
       "  ('kids', 'as', 'such'),\n",
       "  ('as', 'such', 'it'),\n",
       "  ('such', 'it', 'was'),\n",
       "  ('it', 'was', 'successful'),\n",
       "  ('was', 'successful', 'although'),\n",
       "  ('successful', 'although', 'i'),\n",
       "  ('although', 'i', 'liked'),\n",
       "  ('i', 'liked', 'it'),\n",
       "  ('liked', 'it', 'too'),\n",
       "  ('it', 'too', 'personally'),\n",
       "  ('too', 'personally', 'i'),\n",
       "  ('personally', 'i', 'liked'),\n",
       "  ('i', 'liked', 'the'),\n",
       "  ('liked', 'the', 'scrat'),\n",
       "  ('the', 'scrat', ('i', 'saw')),\n",
       "  ('scrat', ('i', 'saw'), ('saw', 'the')),\n",
       "  (('i', 'saw'), ('saw', 'the'), ('the', 'movie')),\n",
       "  (('saw', 'the'), ('the', 'movie'), ('movie', 'with')),\n",
       "  (('the', 'movie'), ('movie', 'with'), ('with', 'two')),\n",
       "  (('movie', 'with'), ('with', 'two'), ('two', 'grown')),\n",
       "  (('with', 'two'), ('two', 'grown'), ('grown', 'children')),\n",
       "  (('two', 'grown'), ('grown', 'children'), ('children', 'although')),\n",
       "  (('grown', 'children'), ('children', 'although'), ('although', 'it')),\n",
       "  (('children', 'although'), ('although', 'it'), ('it', 'was')),\n",
       "  (('although', 'it'), ('it', 'was'), ('was', 'not')),\n",
       "  (('it', 'was'), ('was', 'not'), ('not', 'as')),\n",
       "  (('was', 'not'), ('not', 'as'), ('as', 'clever')),\n",
       "  (('not', 'as'), ('as', 'clever'), ('clever', 'as')),\n",
       "  (('as', 'clever'), ('clever', 'as'), ('as', 'shrek')),\n",
       "  (('clever', 'as'), ('as', 'shrek'), ('shrek', 'i')),\n",
       "  (('as', 'shrek'), ('shrek', 'i'), ('i', 'thought')),\n",
       "  (('shrek', 'i'), ('i', 'thought'), ('thought', 'it')),\n",
       "  (('i', 'thought'), ('thought', 'it'), ('it', 'was')),\n",
       "  (('thought', 'it'), ('it', 'was'), ('was', 'rather')),\n",
       "  (('it', 'was'), ('was', 'rather'), ('rather', 'good')),\n",
       "  (('was', 'rather'), ('rather', 'good'), ('good', 'in')),\n",
       "  (('rather', 'good'), ('good', 'in'), ('in', 'a')),\n",
       "  (('good', 'in'), ('in', 'a'), ('a', 'movie')),\n",
       "  (('in', 'a'), ('a', 'movie'), ('movie', 'theatre')),\n",
       "  (('a', 'movie'), ('movie', 'theatre'), ('theatre', 'surrounded')),\n",
       "  (('movie', 'theatre'), ('theatre', 'surrounded'), ('surrounded', 'by')),\n",
       "  (('theatre', 'surrounded'), ('surrounded', 'by'), ('by', 'children')),\n",
       "  (('surrounded', 'by'), ('by', 'children'), ('children', 'who')),\n",
       "  (('by', 'children'), ('children', 'who'), ('who', 'were')),\n",
       "  (('children', 'who'), ('who', 'were'), ('were', 'on')),\n",
       "  (('who', 'were'), ('were', 'on'), ('on', 'spring')),\n",
       "  (('were', 'on'), ('on', 'spring'), ('spring', 'break')),\n",
       "  (('on', 'spring'), ('spring', 'break'), ('break', 'there')),\n",
       "  (('spring', 'break'), ('break', 'there'), ('there', 'was')),\n",
       "  (('break', 'there'), ('there', 'was'), ('was', 'not')),\n",
       "  (('there', 'was'), ('was', 'not'), ('not', 'a')),\n",
       "  (('was', 'not'), ('not', 'a'), ('a', 'sound')),\n",
       "  (('not', 'a'), ('a', 'sound'), ('sound', 'so')),\n",
       "  (('a', 'sound'), ('sound', 'so'), ('so', 'i')),\n",
       "  (('sound', 'so'), ('so', 'i'), ('i', 'know')),\n",
       "  (('so', 'i'), ('i', 'know'), ('know', 'the')),\n",
       "  (('i', 'know'), ('know', 'the'), ('the', 'children')),\n",
       "  (('know', 'the'), ('the', 'children'), ('children', 'all')),\n",
       "  (('the', 'children'), ('children', 'all'), ('all', 'liked')),\n",
       "  (('children', 'all'), ('all', 'liked'), ('liked', 'it')),\n",
       "  (('all', 'liked'), ('liked', 'it'), ('it', 'there')),\n",
       "  (('liked', 'it'), ('it', 'there'), ('there', 'parents')),\n",
       "  (('it', 'there'), ('there', 'parents'), ('parents', 'also')),\n",
       "  (('there', 'parents'), ('parents', 'also'), ('also', 'seemed')),\n",
       "  (('parents', 'also'), ('also', 'seemed'), ('seemed', 'engaged')),\n",
       "  (('also', 'seemed'), ('seemed', 'engaged'), ('engaged', 'the')),\n",
       "  (('seemed', 'engaged'), ('engaged', 'the'), ('the', 'death')),\n",
       "  (('engaged', 'the'), ('the', 'death'), ('death', 'and')),\n",
       "  (('the', 'death'), ('death', 'and'), ('and', 'apparent')),\n",
       "  (('death', 'and'), ('and', 'apparent'), ('apparent', 'death')),\n",
       "  (('and', 'apparent'), ('apparent', 'death'), ('death', 'of')),\n",
       "  (('apparent', 'death'), ('death', 'of'), ('of', 'characters')),\n",
       "  (('death', 'of'), ('of', 'characters'), ('characters', 'brought')),\n",
       "  (('of', 'characters'), ('characters', 'brought'), ('brought', 'about')),\n",
       "  (('characters', 'brought'), ('brought', 'about'), ('about', 'the')),\n",
       "  (('brought', 'about'), ('about', 'the'), ('the', 'appropriate')),\n",
       "  (('about', 'the'), ('the', 'appropriate'), ('appropriate', 'gasps')),\n",
       "  (('the', 'appropriate'), ('appropriate', 'gasps'), ('gasps', 'and')),\n",
       "  (('appropriate', 'gasps'), ('gasps', 'and'), ('and', 'comments')),\n",
       "  (('gasps', 'and'), ('and', 'comments'), ('comments', 'hopefully')),\n",
       "  (('and', 'comments'), ('comments', 'hopefully'), ('hopefully', 'people')),\n",
       "  (('comments', 'hopefully'), ('hopefully', 'people'), ('people', 'realize')),\n",
       "  (('hopefully', 'people'), ('people', 'realize'), ('realize', 'this')),\n",
       "  (('people', 'realize'), ('realize', 'this'), ('this', 'movie')),\n",
       "  (('realize', 'this'), ('this', 'movie'), ('movie', 'was')),\n",
       "  (('this', 'movie'), ('movie', 'was'), ('was', 'made')),\n",
       "  (('movie', 'was'), ('was', 'made'), ('made', 'for')),\n",
       "  (('was', 'made'), ('made', 'for'), ('for', 'kids')),\n",
       "  (('made', 'for'), ('for', 'kids'), ('kids', 'as')),\n",
       "  (('for', 'kids'), ('kids', 'as'), ('as', 'such')),\n",
       "  (('kids', 'as'), ('as', 'such'), ('such', 'it')),\n",
       "  (('as', 'such'), ('such', 'it'), ('it', 'was')),\n",
       "  (('such', 'it'), ('it', 'was'), ('was', 'successful')),\n",
       "  (('it', 'was'), ('was', 'successful'), ('successful', 'although')),\n",
       "  (('was', 'successful'), ('successful', 'although'), ('although', 'i')),\n",
       "  (('successful', 'although'), ('although', 'i'), ('i', 'liked')),\n",
       "  (('although', 'i'), ('i', 'liked'), ('liked', 'it')),\n",
       "  (('i', 'liked'), ('liked', 'it'), ('it', 'too')),\n",
       "  (('liked', 'it'), ('it', 'too'), ('too', 'personally')),\n",
       "  (('it', 'too'), ('too', 'personally'), ('personally', 'i')),\n",
       "  (('too', 'personally'), ('personally', 'i'), ('i', 'liked')),\n",
       "  (('personally', 'i'), ('i', 'liked'), ('liked', 'the')),\n",
       "  (('i', 'liked'), ('liked', 'the'), ('the', 'scrat'))],\n",
       " [\"you're\",\n",
       "  'using',\n",
       "  'the',\n",
       "  'imdb',\n",
       "  \"you've\",\n",
       "  'given',\n",
       "  'some',\n",
       "  'hefty',\n",
       "  'votes',\n",
       "  'to',\n",
       "  'some',\n",
       "  'of',\n",
       "  'your',\n",
       "  'favourite',\n",
       "  'films',\n",
       "  \"it's\",\n",
       "  'something',\n",
       "  'you',\n",
       "  'enjoy',\n",
       "  'doing',\n",
       "  'and',\n",
       "  \"it's\",\n",
       "  'all',\n",
       "  'because',\n",
       "  'of',\n",
       "  'this',\n",
       "  'fifty',\n",
       "  'seconds',\n",
       "  'one',\n",
       "  'world',\n",
       "  'ends',\n",
       "  'another',\n",
       "  'begins',\n",
       "  'how',\n",
       "  'can',\n",
       "  'it',\n",
       "  'not',\n",
       "  'be',\n",
       "  'given',\n",
       "  'a',\n",
       "  'ten',\n",
       "  'i',\n",
       "  'wonder',\n",
       "  'at',\n",
       "  'those',\n",
       "  'who',\n",
       "  'give',\n",
       "  'this',\n",
       "  'a',\n",
       "  'seven',\n",
       "  'or',\n",
       "  'an',\n",
       "  'eight',\n",
       "  'exactly',\n",
       "  'how',\n",
       "  'could',\n",
       "  'the',\n",
       "  'first',\n",
       "  'film',\n",
       "  'ever',\n",
       "  'made',\n",
       "  'be',\n",
       "  'better',\n",
       "  'for',\n",
       "  'the',\n",
       "  'record',\n",
       "  'the',\n",
       "  'long',\n",
       "  'still',\n",
       "  'opening',\n",
       "  'shot',\n",
       "  'is',\n",
       "  'great',\n",
       "  'showmanship',\n",
       "  'a',\n",
       "  'superb',\n",
       "  'innovation',\n",
       "  'perfectly',\n",
       "  'suited',\n",
       "  'to',\n",
       "  'the',\n",
       "  'situation',\n",
       "  'and',\n",
       "  'the',\n",
       "  'dog',\n",
       "  'on',\n",
       "  'the',\n",
       "  'bike',\n",
       "  'is',\n",
       "  'a',\n",
       "  'lovely',\n",
       "  'touch',\n",
       "  'all',\n",
       "  'this',\n",
       "  'within',\n",
       "  'fifty',\n",
       "  'seconds',\n",
       "  'the',\n",
       "  'word',\n",
       "  'genius',\n",
       "  'is',\n",
       "  'often',\n",
       "  'overused',\n",
       "  'this',\n",
       "  'is',\n",
       "  'genius',\n",
       "  (\"you're\", 'using'),\n",
       "  ('using', 'the'),\n",
       "  ('the', 'imdb'),\n",
       "  ('imdb', \"you've\"),\n",
       "  (\"you've\", 'given'),\n",
       "  ('given', 'some'),\n",
       "  ('some', 'hefty'),\n",
       "  ('hefty', 'votes'),\n",
       "  ('votes', 'to'),\n",
       "  ('to', 'some'),\n",
       "  ('some', 'of'),\n",
       "  ('of', 'your'),\n",
       "  ('your', 'favourite'),\n",
       "  ('favourite', 'films'),\n",
       "  ('films', \"it's\"),\n",
       "  (\"it's\", 'something'),\n",
       "  ('something', 'you'),\n",
       "  ('you', 'enjoy'),\n",
       "  ('enjoy', 'doing'),\n",
       "  ('doing', 'and'),\n",
       "  ('and', \"it's\"),\n",
       "  (\"it's\", 'all'),\n",
       "  ('all', 'because'),\n",
       "  ('because', 'of'),\n",
       "  ('of', 'this'),\n",
       "  ('this', 'fifty'),\n",
       "  ('fifty', 'seconds'),\n",
       "  ('seconds', 'one'),\n",
       "  ('one', 'world'),\n",
       "  ('world', 'ends'),\n",
       "  ('ends', 'another'),\n",
       "  ('another', 'begins'),\n",
       "  ('begins', 'how'),\n",
       "  ('how', 'can'),\n",
       "  ('can', 'it'),\n",
       "  ('it', 'not'),\n",
       "  ('not', 'be'),\n",
       "  ('be', 'given'),\n",
       "  ('given', 'a'),\n",
       "  ('a', 'ten'),\n",
       "  ('ten', 'i'),\n",
       "  ('i', 'wonder'),\n",
       "  ('wonder', 'at'),\n",
       "  ('at', 'those'),\n",
       "  ('those', 'who'),\n",
       "  ('who', 'give'),\n",
       "  ('give', 'this'),\n",
       "  ('this', 'a'),\n",
       "  ('a', 'seven'),\n",
       "  ('seven', 'or'),\n",
       "  ('or', 'an'),\n",
       "  ('an', 'eight'),\n",
       "  ('eight', 'exactly'),\n",
       "  ('exactly', 'how'),\n",
       "  ('how', 'could'),\n",
       "  ('could', 'the'),\n",
       "  ('the', 'first'),\n",
       "  ('first', 'film'),\n",
       "  ('film', 'ever'),\n",
       "  ('ever', 'made'),\n",
       "  ('made', 'be'),\n",
       "  ('be', 'better'),\n",
       "  ('better', 'for'),\n",
       "  ('for', 'the'),\n",
       "  ('the', 'record'),\n",
       "  ('record', 'the'),\n",
       "  ('the', 'long'),\n",
       "  ('long', 'still'),\n",
       "  ('still', 'opening'),\n",
       "  ('opening', 'shot'),\n",
       "  ('shot', 'is'),\n",
       "  ('is', 'great'),\n",
       "  ('great', 'showmanship'),\n",
       "  ('showmanship', 'a'),\n",
       "  ('a', 'superb'),\n",
       "  ('superb', 'innovation'),\n",
       "  ('innovation', 'perfectly'),\n",
       "  ('perfectly', 'suited'),\n",
       "  ('suited', 'to'),\n",
       "  ('to', 'the'),\n",
       "  ('the', 'situation'),\n",
       "  ('situation', 'and'),\n",
       "  ('and', 'the'),\n",
       "  ('the', 'dog'),\n",
       "  ('dog', 'on'),\n",
       "  ('on', 'the'),\n",
       "  ('the', 'bike'),\n",
       "  ('bike', 'is'),\n",
       "  ('is', 'a'),\n",
       "  ('a', 'lovely'),\n",
       "  ('lovely', 'touch'),\n",
       "  ('touch', 'all'),\n",
       "  ('all', 'this'),\n",
       "  ('this', 'within'),\n",
       "  ('within', 'fifty'),\n",
       "  ('fifty', 'seconds'),\n",
       "  ('seconds', 'the'),\n",
       "  ('the', 'word'),\n",
       "  ('word', 'genius'),\n",
       "  ('genius', 'is'),\n",
       "  ('is', 'often'),\n",
       "  ('often', 'overused'),\n",
       "  ('overused', 'this'),\n",
       "  ('this', 'is'),\n",
       "  ('is', 'genius'),\n",
       "  (\"you're\", 'using', 'the'),\n",
       "  ('using', 'the', 'imdb'),\n",
       "  ('the', 'imdb', \"you've\"),\n",
       "  ('imdb', \"you've\", 'given'),\n",
       "  (\"you've\", 'given', 'some'),\n",
       "  ('given', 'some', 'hefty'),\n",
       "  ('some', 'hefty', 'votes'),\n",
       "  ('hefty', 'votes', 'to'),\n",
       "  ('votes', 'to', 'some'),\n",
       "  ('to', 'some', 'of'),\n",
       "  ('some', 'of', 'your'),\n",
       "  ('of', 'your', 'favourite'),\n",
       "  ('your', 'favourite', 'films'),\n",
       "  ('favourite', 'films', \"it's\"),\n",
       "  ('films', \"it's\", 'something'),\n",
       "  (\"it's\", 'something', 'you'),\n",
       "  ('something', 'you', 'enjoy'),\n",
       "  ('you', 'enjoy', 'doing'),\n",
       "  ('enjoy', 'doing', 'and'),\n",
       "  ('doing', 'and', \"it's\"),\n",
       "  ('and', \"it's\", 'all'),\n",
       "  (\"it's\", 'all', 'because'),\n",
       "  ('all', 'because', 'of'),\n",
       "  ('because', 'of', 'this'),\n",
       "  ('of', 'this', 'fifty'),\n",
       "  ('this', 'fifty', 'seconds'),\n",
       "  ('fifty', 'seconds', 'one'),\n",
       "  ('seconds', 'one', 'world'),\n",
       "  ('one', 'world', 'ends'),\n",
       "  ('world', 'ends', 'another'),\n",
       "  ('ends', 'another', 'begins'),\n",
       "  ('another', 'begins', 'how'),\n",
       "  ('begins', 'how', 'can'),\n",
       "  ('how', 'can', 'it'),\n",
       "  ('can', 'it', 'not'),\n",
       "  ('it', 'not', 'be'),\n",
       "  ('not', 'be', 'given'),\n",
       "  ('be', 'given', 'a'),\n",
       "  ('given', 'a', 'ten'),\n",
       "  ('a', 'ten', 'i'),\n",
       "  ('ten', 'i', 'wonder'),\n",
       "  ('i', 'wonder', 'at'),\n",
       "  ('wonder', 'at', 'those'),\n",
       "  ('at', 'those', 'who'),\n",
       "  ('those', 'who', 'give'),\n",
       "  ('who', 'give', 'this'),\n",
       "  ('give', 'this', 'a'),\n",
       "  ('this', 'a', 'seven'),\n",
       "  ('a', 'seven', 'or'),\n",
       "  ('seven', 'or', 'an'),\n",
       "  ('or', 'an', 'eight'),\n",
       "  ('an', 'eight', 'exactly'),\n",
       "  ('eight', 'exactly', 'how'),\n",
       "  ('exactly', 'how', 'could'),\n",
       "  ('how', 'could', 'the'),\n",
       "  ('could', 'the', 'first'),\n",
       "  ('the', 'first', 'film'),\n",
       "  ('first', 'film', 'ever'),\n",
       "  ('film', 'ever', 'made'),\n",
       "  ('ever', 'made', 'be'),\n",
       "  ('made', 'be', 'better'),\n",
       "  ('be', 'better', 'for'),\n",
       "  ('better', 'for', 'the'),\n",
       "  ('for', 'the', 'record'),\n",
       "  ('the', 'record', 'the'),\n",
       "  ('record', 'the', 'long'),\n",
       "  ('the', 'long', 'still'),\n",
       "  ('long', 'still', 'opening'),\n",
       "  ('still', 'opening', 'shot'),\n",
       "  ('opening', 'shot', 'is'),\n",
       "  ('shot', 'is', 'great'),\n",
       "  ('is', 'great', 'showmanship'),\n",
       "  ('great', 'showmanship', 'a'),\n",
       "  ('showmanship', 'a', 'superb'),\n",
       "  ('a', 'superb', 'innovation'),\n",
       "  ('superb', 'innovation', 'perfectly'),\n",
       "  ('innovation', 'perfectly', 'suited'),\n",
       "  ('perfectly', 'suited', 'to'),\n",
       "  ('suited', 'to', 'the'),\n",
       "  ('to', 'the', 'situation'),\n",
       "  ('the', 'situation', 'and'),\n",
       "  ('situation', 'and', 'the'),\n",
       "  ('and', 'the', 'dog'),\n",
       "  ('the', 'dog', 'on'),\n",
       "  ('dog', 'on', 'the'),\n",
       "  ('on', 'the', 'bike'),\n",
       "  ('the', 'bike', 'is'),\n",
       "  ('bike', 'is', 'a'),\n",
       "  ('is', 'a', 'lovely'),\n",
       "  ('a', 'lovely', 'touch'),\n",
       "  ('lovely', 'touch', 'all'),\n",
       "  ('touch', 'all', 'this'),\n",
       "  ('all', 'this', 'within'),\n",
       "  ('this', 'within', 'fifty'),\n",
       "  ('within', 'fifty', 'seconds'),\n",
       "  ('fifty', 'seconds', 'the'),\n",
       "  ('seconds', 'the', 'word'),\n",
       "  ('the', 'word', 'genius'),\n",
       "  ('word', 'genius', 'is'),\n",
       "  ('genius', 'is', 'often'),\n",
       "  ('is', 'often', 'overused'),\n",
       "  ('often', 'overused', 'this'),\n",
       "  ('overused', 'this', 'is'),\n",
       "  ('this', 'is', 'genius'),\n",
       "  ('is', 'genius', (\"you're\", 'using')),\n",
       "  ('genius', (\"you're\", 'using'), ('using', 'the')),\n",
       "  ((\"you're\", 'using'), ('using', 'the'), ('the', 'imdb')),\n",
       "  (('using', 'the'), ('the', 'imdb'), ('imdb', \"you've\")),\n",
       "  (('the', 'imdb'), ('imdb', \"you've\"), (\"you've\", 'given')),\n",
       "  (('imdb', \"you've\"), (\"you've\", 'given'), ('given', 'some')),\n",
       "  ((\"you've\", 'given'), ('given', 'some'), ('some', 'hefty')),\n",
       "  (('given', 'some'), ('some', 'hefty'), ('hefty', 'votes')),\n",
       "  (('some', 'hefty'), ('hefty', 'votes'), ('votes', 'to')),\n",
       "  (('hefty', 'votes'), ('votes', 'to'), ('to', 'some')),\n",
       "  (('votes', 'to'), ('to', 'some'), ('some', 'of')),\n",
       "  (('to', 'some'), ('some', 'of'), ('of', 'your')),\n",
       "  (('some', 'of'), ('of', 'your'), ('your', 'favourite')),\n",
       "  (('of', 'your'), ('your', 'favourite'), ('favourite', 'films')),\n",
       "  (('your', 'favourite'), ('favourite', 'films'), ('films', \"it's\")),\n",
       "  (('favourite', 'films'), ('films', \"it's\"), (\"it's\", 'something')),\n",
       "  (('films', \"it's\"), (\"it's\", 'something'), ('something', 'you')),\n",
       "  ((\"it's\", 'something'), ('something', 'you'), ('you', 'enjoy')),\n",
       "  (('something', 'you'), ('you', 'enjoy'), ('enjoy', 'doing')),\n",
       "  (('you', 'enjoy'), ('enjoy', 'doing'), ('doing', 'and')),\n",
       "  (('enjoy', 'doing'), ('doing', 'and'), ('and', \"it's\")),\n",
       "  (('doing', 'and'), ('and', \"it's\"), (\"it's\", 'all')),\n",
       "  (('and', \"it's\"), (\"it's\", 'all'), ('all', 'because')),\n",
       "  ((\"it's\", 'all'), ('all', 'because'), ('because', 'of')),\n",
       "  (('all', 'because'), ('because', 'of'), ('of', 'this')),\n",
       "  (('because', 'of'), ('of', 'this'), ('this', 'fifty')),\n",
       "  (('of', 'this'), ('this', 'fifty'), ('fifty', 'seconds')),\n",
       "  (('this', 'fifty'), ('fifty', 'seconds'), ('seconds', 'one')),\n",
       "  (('fifty', 'seconds'), ('seconds', 'one'), ('one', 'world')),\n",
       "  (('seconds', 'one'), ('one', 'world'), ('world', 'ends')),\n",
       "  (('one', 'world'), ('world', 'ends'), ('ends', 'another')),\n",
       "  (('world', 'ends'), ('ends', 'another'), ('another', 'begins')),\n",
       "  (('ends', 'another'), ('another', 'begins'), ('begins', 'how')),\n",
       "  (('another', 'begins'), ('begins', 'how'), ('how', 'can')),\n",
       "  (('begins', 'how'), ('how', 'can'), ('can', 'it')),\n",
       "  (('how', 'can'), ('can', 'it'), ('it', 'not')),\n",
       "  (('can', 'it'), ('it', 'not'), ('not', 'be')),\n",
       "  (('it', 'not'), ('not', 'be'), ('be', 'given')),\n",
       "  (('not', 'be'), ('be', 'given'), ('given', 'a')),\n",
       "  (('be', 'given'), ('given', 'a'), ('a', 'ten')),\n",
       "  (('given', 'a'), ('a', 'ten'), ('ten', 'i')),\n",
       "  (('a', 'ten'), ('ten', 'i'), ('i', 'wonder')),\n",
       "  (('ten', 'i'), ('i', 'wonder'), ('wonder', 'at')),\n",
       "  (('i', 'wonder'), ('wonder', 'at'), ('at', 'those')),\n",
       "  (('wonder', 'at'), ('at', 'those'), ('those', 'who')),\n",
       "  (('at', 'those'), ('those', 'who'), ('who', 'give')),\n",
       "  (('those', 'who'), ('who', 'give'), ('give', 'this')),\n",
       "  (('who', 'give'), ('give', 'this'), ('this', 'a')),\n",
       "  (('give', 'this'), ('this', 'a'), ('a', 'seven')),\n",
       "  (('this', 'a'), ('a', 'seven'), ('seven', 'or')),\n",
       "  (('a', 'seven'), ('seven', 'or'), ('or', 'an')),\n",
       "  (('seven', 'or'), ('or', 'an'), ('an', 'eight')),\n",
       "  (('or', 'an'), ('an', 'eight'), ('eight', 'exactly')),\n",
       "  (('an', 'eight'), ('eight', 'exactly'), ('exactly', 'how')),\n",
       "  (('eight', 'exactly'), ('exactly', 'how'), ('how', 'could')),\n",
       "  (('exactly', 'how'), ('how', 'could'), ('could', 'the')),\n",
       "  (('how', 'could'), ('could', 'the'), ('the', 'first')),\n",
       "  (('could', 'the'), ('the', 'first'), ('first', 'film')),\n",
       "  (('the', 'first'), ('first', 'film'), ('film', 'ever')),\n",
       "  (('first', 'film'), ('film', 'ever'), ('ever', 'made')),\n",
       "  (('film', 'ever'), ('ever', 'made'), ('made', 'be')),\n",
       "  (('ever', 'made'), ('made', 'be'), ('be', 'better')),\n",
       "  (('made', 'be'), ('be', 'better'), ('better', 'for')),\n",
       "  (('be', 'better'), ('better', 'for'), ('for', 'the')),\n",
       "  (('better', 'for'), ('for', 'the'), ('the', 'record')),\n",
       "  (('for', 'the'), ('the', 'record'), ('record', 'the')),\n",
       "  (('the', 'record'), ('record', 'the'), ('the', 'long')),\n",
       "  (('record', 'the'), ('the', 'long'), ('long', 'still')),\n",
       "  (('the', 'long'), ('long', 'still'), ('still', 'opening')),\n",
       "  (('long', 'still'), ('still', 'opening'), ('opening', 'shot')),\n",
       "  (('still', 'opening'), ('opening', 'shot'), ('shot', 'is')),\n",
       "  (('opening', 'shot'), ('shot', 'is'), ('is', 'great')),\n",
       "  (('shot', 'is'), ('is', 'great'), ('great', 'showmanship')),\n",
       "  (('is', 'great'), ('great', 'showmanship'), ('showmanship', 'a')),\n",
       "  (('great', 'showmanship'), ('showmanship', 'a'), ('a', 'superb')),\n",
       "  (('showmanship', 'a'), ('a', 'superb'), ('superb', 'innovation')),\n",
       "  (('a', 'superb'), ('superb', 'innovation'), ('innovation', 'perfectly')),\n",
       "  (('superb', 'innovation'),\n",
       "   ('innovation', 'perfectly'),\n",
       "   ('perfectly', 'suited')),\n",
       "  (('innovation', 'perfectly'), ('perfectly', 'suited'), ('suited', 'to')),\n",
       "  (('perfectly', 'suited'), ('suited', 'to'), ('to', 'the')),\n",
       "  (('suited', 'to'), ('to', 'the'), ('the', 'situation')),\n",
       "  (('to', 'the'), ('the', 'situation'), ('situation', 'and')),\n",
       "  (('the', 'situation'), ('situation', 'and'), ('and', 'the')),\n",
       "  (('situation', 'and'), ('and', 'the'), ('the', 'dog')),\n",
       "  (('and', 'the'), ('the', 'dog'), ('dog', 'on')),\n",
       "  (('the', 'dog'), ('dog', 'on'), ('on', 'the')),\n",
       "  (('dog', 'on'), ('on', 'the'), ('the', 'bike')),\n",
       "  (('on', 'the'), ('the', 'bike'), ('bike', 'is')),\n",
       "  (('the', 'bike'), ('bike', 'is'), ('is', 'a')),\n",
       "  (('bike', 'is'), ('is', 'a'), ('a', 'lovely')),\n",
       "  (('is', 'a'), ('a', 'lovely'), ('lovely', 'touch')),\n",
       "  (('a', 'lovely'), ('lovely', 'touch'), ('touch', 'all')),\n",
       "  (('lovely', 'touch'), ('touch', 'all'), ('all', 'this')),\n",
       "  (('touch', 'all'), ('all', 'this'), ('this', 'within')),\n",
       "  (('all', 'this'), ('this', 'within'), ('within', 'fifty')),\n",
       "  (('this', 'within'), ('within', 'fifty'), ('fifty', 'seconds')),\n",
       "  (('within', 'fifty'), ('fifty', 'seconds'), ('seconds', 'the')),\n",
       "  (('fifty', 'seconds'), ('seconds', 'the'), ('the', 'word')),\n",
       "  (('seconds', 'the'), ('the', 'word'), ('word', 'genius')),\n",
       "  (('the', 'word'), ('word', 'genius'), ('genius', 'is')),\n",
       "  (('word', 'genius'), ('genius', 'is'), ('is', 'often')),\n",
       "  (('genius', 'is'), ('is', 'often'), ('often', 'overused')),\n",
       "  (('is', 'often'), ('often', 'overused'), ('overused', 'this')),\n",
       "  (('often', 'overused'), ('overused', 'this'), ('this', 'is')),\n",
       "  (('overused', 'this'), ('this', 'is'), ('is', 'genius'))]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_tokens[5:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenization function \n",
    "\n",
    "# import spacy\n",
    "# import string\n",
    "# import pickle as pkl\n",
    "# import random\n",
    "\n",
    "# # Load English tokenizer, tagger, parser, NER and word vectors\n",
    "# tokenizer = spacy.load('en_core_web_sm')\n",
    "# punctuations = string.punctuation\n",
    "\n",
    "# # lowercase and remove punctuation, returns a list of tokens\n",
    "# def tokenize(sent):\n",
    "#   tokens = tokenizer(sent)\n",
    "#   return [token.text.lower() for token in tokens if (token.text not in punctuations)]\n",
    "\n",
    "# def tokenize_dataset(dataset):\n",
    "#     token_dataset = []\n",
    "#     # we are keeping track of all tokens in dataset \n",
    "#     # in order to create vocabulary later\n",
    "#     all_tokens = []\n",
    "    \n",
    "#     for sample in dataset:\n",
    "#         tokens = tokenize(sample)\n",
    "#         token_dataset.append(tokens)\n",
    "#         all_tokens += tokens\n",
    "\n",
    "#     return token_dataset, all_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #val set tokens\n",
    "# print (\"Tokenizing val data\")\n",
    "# val_data_tokens, _ = tokenize_dataset(val_data)\n",
    "# pkl.dump(val_data_tokens, open(\"val_data_tokens.p\", \"wb\"))\n",
    "\n",
    "# #test set tokens\n",
    "# print (\"Tokenizing test data\")\n",
    "# test_data_tokens, _ = tokenize_dataset(test_data)\n",
    "# pkl.dump(test_data_tokens, open(\"test_data_tokens.p\", \"wb\"))\n",
    "\n",
    "# #train set tokens\n",
    "# print (\"Tokenizing train data\")\n",
    "# train_data_tokens, all_train_tokens = tokenize_dataset(train_data)\n",
    "# pkl.dump(train_data_tokens, open(\"train_data_tokens.p\", \"wb\"))\n",
    "# pkl.dump(all_train_tokens, open(\"all_train_tokens.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pickle files\n",
    "# import pickle as pkl\n",
    "\n",
    "# train_data_tokens = pkl.load(open(\"train_data_tokens.p\", \"rb\"))\n",
    "# all_train_tokens = pkl.load(open(\"all_train_tokens.p\", \"rb\"))\n",
    "\n",
    "# val_data_tokens = pkl.load(open(\"val_data_tokens.p\", \"rb\"))\n",
    "# test_data_tokens = pkl.load(open(\"test_data_tokens.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['i',\n",
       "  'saw',\n",
       "  'the',\n",
       "  'movie',\n",
       "  'with',\n",
       "  'two',\n",
       "  'grown',\n",
       "  'children',\n",
       "  'although',\n",
       "  'it',\n",
       "  'was',\n",
       "  'not',\n",
       "  'as',\n",
       "  'clever',\n",
       "  'as',\n",
       "  'shrek',\n",
       "  'i',\n",
       "  'thought',\n",
       "  'it',\n",
       "  'was',\n",
       "  'rather',\n",
       "  'good',\n",
       "  'in',\n",
       "  'a',\n",
       "  'movie',\n",
       "  'theatre',\n",
       "  'surrounded',\n",
       "  'by',\n",
       "  'children',\n",
       "  'who',\n",
       "  'were',\n",
       "  'on',\n",
       "  'spring',\n",
       "  'break',\n",
       "  'there',\n",
       "  'was',\n",
       "  'not',\n",
       "  'a',\n",
       "  'sound',\n",
       "  'so',\n",
       "  'i',\n",
       "  'know',\n",
       "  'the',\n",
       "  'children',\n",
       "  'all',\n",
       "  'liked',\n",
       "  'it',\n",
       "  'there',\n",
       "  'parents',\n",
       "  'also',\n",
       "  'seemed',\n",
       "  'engaged',\n",
       "  'the',\n",
       "  'death',\n",
       "  'and',\n",
       "  'apparent',\n",
       "  'death',\n",
       "  'of',\n",
       "  'characters',\n",
       "  'brought',\n",
       "  'about',\n",
       "  'the',\n",
       "  'appropriate',\n",
       "  'gasps',\n",
       "  'and',\n",
       "  'comments',\n",
       "  'hopefully',\n",
       "  'people',\n",
       "  'realize',\n",
       "  'this',\n",
       "  'movie',\n",
       "  'was',\n",
       "  'made',\n",
       "  'for',\n",
       "  'kids',\n",
       "  'as',\n",
       "  'such',\n",
       "  'it',\n",
       "  'was',\n",
       "  'successful',\n",
       "  'although',\n",
       "  'i',\n",
       "  'liked',\n",
       "  'it',\n",
       "  'too',\n",
       "  'personally',\n",
       "  'i',\n",
       "  'liked',\n",
       "  'the',\n",
       "  'scrat',\n",
       "  ('i', 'saw'),\n",
       "  ('saw', 'the'),\n",
       "  ('the', 'movie'),\n",
       "  ('movie', 'with'),\n",
       "  ('with', 'two'),\n",
       "  ('two', 'grown'),\n",
       "  ('grown', 'children'),\n",
       "  ('children', 'although'),\n",
       "  ('although', 'it'),\n",
       "  ('it', 'was'),\n",
       "  ('was', 'not'),\n",
       "  ('not', 'as'),\n",
       "  ('as', 'clever'),\n",
       "  ('clever', 'as'),\n",
       "  ('as', 'shrek'),\n",
       "  ('shrek', 'i'),\n",
       "  ('i', 'thought'),\n",
       "  ('thought', 'it'),\n",
       "  ('it', 'was'),\n",
       "  ('was', 'rather'),\n",
       "  ('rather', 'good'),\n",
       "  ('good', 'in'),\n",
       "  ('in', 'a'),\n",
       "  ('a', 'movie'),\n",
       "  ('movie', 'theatre'),\n",
       "  ('theatre', 'surrounded'),\n",
       "  ('surrounded', 'by'),\n",
       "  ('by', 'children'),\n",
       "  ('children', 'who'),\n",
       "  ('who', 'were'),\n",
       "  ('were', 'on'),\n",
       "  ('on', 'spring'),\n",
       "  ('spring', 'break'),\n",
       "  ('break', 'there'),\n",
       "  ('there', 'was'),\n",
       "  ('was', 'not'),\n",
       "  ('not', 'a'),\n",
       "  ('a', 'sound'),\n",
       "  ('sound', 'so'),\n",
       "  ('so', 'i'),\n",
       "  ('i', 'know'),\n",
       "  ('know', 'the'),\n",
       "  ('the', 'children'),\n",
       "  ('children', 'all'),\n",
       "  ('all', 'liked'),\n",
       "  ('liked', 'it'),\n",
       "  ('it', 'there'),\n",
       "  ('there', 'parents'),\n",
       "  ('parents', 'also'),\n",
       "  ('also', 'seemed'),\n",
       "  ('seemed', 'engaged'),\n",
       "  ('engaged', 'the'),\n",
       "  ('the', 'death'),\n",
       "  ('death', 'and'),\n",
       "  ('and', 'apparent'),\n",
       "  ('apparent', 'death'),\n",
       "  ('death', 'of'),\n",
       "  ('of', 'characters'),\n",
       "  ('characters', 'brought'),\n",
       "  ('brought', 'about'),\n",
       "  ('about', 'the'),\n",
       "  ('the', 'appropriate'),\n",
       "  ('appropriate', 'gasps'),\n",
       "  ('gasps', 'and'),\n",
       "  ('and', 'comments'),\n",
       "  ('comments', 'hopefully'),\n",
       "  ('hopefully', 'people'),\n",
       "  ('people', 'realize'),\n",
       "  ('realize', 'this'),\n",
       "  ('this', 'movie'),\n",
       "  ('movie', 'was'),\n",
       "  ('was', 'made'),\n",
       "  ('made', 'for'),\n",
       "  ('for', 'kids'),\n",
       "  ('kids', 'as'),\n",
       "  ('as', 'such'),\n",
       "  ('such', 'it'),\n",
       "  ('it', 'was'),\n",
       "  ('was', 'successful'),\n",
       "  ('successful', 'although'),\n",
       "  ('although', 'i'),\n",
       "  ('i', 'liked'),\n",
       "  ('liked', 'it'),\n",
       "  ('it', 'too'),\n",
       "  ('too', 'personally'),\n",
       "  ('personally', 'i'),\n",
       "  ('i', 'liked'),\n",
       "  ('liked', 'the'),\n",
       "  ('the', 'scrat'),\n",
       "  ('i', 'saw', 'the'),\n",
       "  ('saw', 'the', 'movie'),\n",
       "  ('the', 'movie', 'with'),\n",
       "  ('movie', 'with', 'two'),\n",
       "  ('with', 'two', 'grown'),\n",
       "  ('two', 'grown', 'children'),\n",
       "  ('grown', 'children', 'although'),\n",
       "  ('children', 'although', 'it'),\n",
       "  ('although', 'it', 'was'),\n",
       "  ('it', 'was', 'not'),\n",
       "  ('was', 'not', 'as'),\n",
       "  ('not', 'as', 'clever'),\n",
       "  ('as', 'clever', 'as'),\n",
       "  ('clever', 'as', 'shrek'),\n",
       "  ('as', 'shrek', 'i'),\n",
       "  ('shrek', 'i', 'thought'),\n",
       "  ('i', 'thought', 'it'),\n",
       "  ('thought', 'it', 'was'),\n",
       "  ('it', 'was', 'rather'),\n",
       "  ('was', 'rather', 'good'),\n",
       "  ('rather', 'good', 'in'),\n",
       "  ('good', 'in', 'a'),\n",
       "  ('in', 'a', 'movie'),\n",
       "  ('a', 'movie', 'theatre'),\n",
       "  ('movie', 'theatre', 'surrounded'),\n",
       "  ('theatre', 'surrounded', 'by'),\n",
       "  ('surrounded', 'by', 'children'),\n",
       "  ('by', 'children', 'who'),\n",
       "  ('children', 'who', 'were'),\n",
       "  ('who', 'were', 'on'),\n",
       "  ('were', 'on', 'spring'),\n",
       "  ('on', 'spring', 'break'),\n",
       "  ('spring', 'break', 'there'),\n",
       "  ('break', 'there', 'was'),\n",
       "  ('there', 'was', 'not'),\n",
       "  ('was', 'not', 'a'),\n",
       "  ('not', 'a', 'sound'),\n",
       "  ('a', 'sound', 'so'),\n",
       "  ('sound', 'so', 'i'),\n",
       "  ('so', 'i', 'know'),\n",
       "  ('i', 'know', 'the'),\n",
       "  ('know', 'the', 'children'),\n",
       "  ('the', 'children', 'all'),\n",
       "  ('children', 'all', 'liked'),\n",
       "  ('all', 'liked', 'it'),\n",
       "  ('liked', 'it', 'there'),\n",
       "  ('it', 'there', 'parents'),\n",
       "  ('there', 'parents', 'also'),\n",
       "  ('parents', 'also', 'seemed'),\n",
       "  ('also', 'seemed', 'engaged'),\n",
       "  ('seemed', 'engaged', 'the'),\n",
       "  ('engaged', 'the', 'death'),\n",
       "  ('the', 'death', 'and'),\n",
       "  ('death', 'and', 'apparent'),\n",
       "  ('and', 'apparent', 'death'),\n",
       "  ('apparent', 'death', 'of'),\n",
       "  ('death', 'of', 'characters'),\n",
       "  ('of', 'characters', 'brought'),\n",
       "  ('characters', 'brought', 'about'),\n",
       "  ('brought', 'about', 'the'),\n",
       "  ('about', 'the', 'appropriate'),\n",
       "  ('the', 'appropriate', 'gasps'),\n",
       "  ('appropriate', 'gasps', 'and'),\n",
       "  ('gasps', 'and', 'comments'),\n",
       "  ('and', 'comments', 'hopefully'),\n",
       "  ('comments', 'hopefully', 'people'),\n",
       "  ('hopefully', 'people', 'realize'),\n",
       "  ('people', 'realize', 'this'),\n",
       "  ('realize', 'this', 'movie'),\n",
       "  ('this', 'movie', 'was'),\n",
       "  ('movie', 'was', 'made'),\n",
       "  ('was', 'made', 'for'),\n",
       "  ('made', 'for', 'kids'),\n",
       "  ('for', 'kids', 'as'),\n",
       "  ('kids', 'as', 'such'),\n",
       "  ('as', 'such', 'it'),\n",
       "  ('such', 'it', 'was'),\n",
       "  ('it', 'was', 'successful'),\n",
       "  ('was', 'successful', 'although'),\n",
       "  ('successful', 'although', 'i'),\n",
       "  ('although', 'i', 'liked'),\n",
       "  ('i', 'liked', 'it'),\n",
       "  ('liked', 'it', 'too'),\n",
       "  ('it', 'too', 'personally'),\n",
       "  ('too', 'personally', 'i'),\n",
       "  ('personally', 'i', 'liked'),\n",
       "  ('i', 'liked', 'the'),\n",
       "  ('liked', 'the', 'scrat'),\n",
       "  ('the', 'scrat', ('i', 'saw')),\n",
       "  ('scrat', ('i', 'saw'), ('saw', 'the')),\n",
       "  (('i', 'saw'), ('saw', 'the'), ('the', 'movie')),\n",
       "  (('saw', 'the'), ('the', 'movie'), ('movie', 'with')),\n",
       "  (('the', 'movie'), ('movie', 'with'), ('with', 'two')),\n",
       "  (('movie', 'with'), ('with', 'two'), ('two', 'grown')),\n",
       "  (('with', 'two'), ('two', 'grown'), ('grown', 'children')),\n",
       "  (('two', 'grown'), ('grown', 'children'), ('children', 'although')),\n",
       "  (('grown', 'children'), ('children', 'although'), ('although', 'it')),\n",
       "  (('children', 'although'), ('although', 'it'), ('it', 'was')),\n",
       "  (('although', 'it'), ('it', 'was'), ('was', 'not')),\n",
       "  (('it', 'was'), ('was', 'not'), ('not', 'as')),\n",
       "  (('was', 'not'), ('not', 'as'), ('as', 'clever')),\n",
       "  (('not', 'as'), ('as', 'clever'), ('clever', 'as')),\n",
       "  (('as', 'clever'), ('clever', 'as'), ('as', 'shrek')),\n",
       "  (('clever', 'as'), ('as', 'shrek'), ('shrek', 'i')),\n",
       "  (('as', 'shrek'), ('shrek', 'i'), ('i', 'thought')),\n",
       "  (('shrek', 'i'), ('i', 'thought'), ('thought', 'it')),\n",
       "  (('i', 'thought'), ('thought', 'it'), ('it', 'was')),\n",
       "  (('thought', 'it'), ('it', 'was'), ('was', 'rather')),\n",
       "  (('it', 'was'), ('was', 'rather'), ('rather', 'good')),\n",
       "  (('was', 'rather'), ('rather', 'good'), ('good', 'in')),\n",
       "  (('rather', 'good'), ('good', 'in'), ('in', 'a')),\n",
       "  (('good', 'in'), ('in', 'a'), ('a', 'movie')),\n",
       "  (('in', 'a'), ('a', 'movie'), ('movie', 'theatre')),\n",
       "  (('a', 'movie'), ('movie', 'theatre'), ('theatre', 'surrounded')),\n",
       "  (('movie', 'theatre'), ('theatre', 'surrounded'), ('surrounded', 'by')),\n",
       "  (('theatre', 'surrounded'), ('surrounded', 'by'), ('by', 'children')),\n",
       "  (('surrounded', 'by'), ('by', 'children'), ('children', 'who')),\n",
       "  (('by', 'children'), ('children', 'who'), ('who', 'were')),\n",
       "  (('children', 'who'), ('who', 'were'), ('were', 'on')),\n",
       "  (('who', 'were'), ('were', 'on'), ('on', 'spring')),\n",
       "  (('were', 'on'), ('on', 'spring'), ('spring', 'break')),\n",
       "  (('on', 'spring'), ('spring', 'break'), ('break', 'there')),\n",
       "  (('spring', 'break'), ('break', 'there'), ('there', 'was')),\n",
       "  (('break', 'there'), ('there', 'was'), ('was', 'not')),\n",
       "  (('there', 'was'), ('was', 'not'), ('not', 'a')),\n",
       "  (('was', 'not'), ('not', 'a'), ('a', 'sound')),\n",
       "  (('not', 'a'), ('a', 'sound'), ('sound', 'so')),\n",
       "  (('a', 'sound'), ('sound', 'so'), ('so', 'i')),\n",
       "  (('sound', 'so'), ('so', 'i'), ('i', 'know')),\n",
       "  (('so', 'i'), ('i', 'know'), ('know', 'the')),\n",
       "  (('i', 'know'), ('know', 'the'), ('the', 'children')),\n",
       "  (('know', 'the'), ('the', 'children'), ('children', 'all')),\n",
       "  (('the', 'children'), ('children', 'all'), ('all', 'liked')),\n",
       "  (('children', 'all'), ('all', 'liked'), ('liked', 'it')),\n",
       "  (('all', 'liked'), ('liked', 'it'), ('it', 'there')),\n",
       "  (('liked', 'it'), ('it', 'there'), ('there', 'parents')),\n",
       "  (('it', 'there'), ('there', 'parents'), ('parents', 'also')),\n",
       "  (('there', 'parents'), ('parents', 'also'), ('also', 'seemed')),\n",
       "  (('parents', 'also'), ('also', 'seemed'), ('seemed', 'engaged')),\n",
       "  (('also', 'seemed'), ('seemed', 'engaged'), ('engaged', 'the')),\n",
       "  (('seemed', 'engaged'), ('engaged', 'the'), ('the', 'death')),\n",
       "  (('engaged', 'the'), ('the', 'death'), ('death', 'and')),\n",
       "  (('the', 'death'), ('death', 'and'), ('and', 'apparent')),\n",
       "  (('death', 'and'), ('and', 'apparent'), ('apparent', 'death')),\n",
       "  (('and', 'apparent'), ('apparent', 'death'), ('death', 'of')),\n",
       "  (('apparent', 'death'), ('death', 'of'), ('of', 'characters')),\n",
       "  (('death', 'of'), ('of', 'characters'), ('characters', 'brought')),\n",
       "  (('of', 'characters'), ('characters', 'brought'), ('brought', 'about')),\n",
       "  (('characters', 'brought'), ('brought', 'about'), ('about', 'the')),\n",
       "  (('brought', 'about'), ('about', 'the'), ('the', 'appropriate')),\n",
       "  (('about', 'the'), ('the', 'appropriate'), ('appropriate', 'gasps')),\n",
       "  (('the', 'appropriate'), ('appropriate', 'gasps'), ('gasps', 'and')),\n",
       "  (('appropriate', 'gasps'), ('gasps', 'and'), ('and', 'comments')),\n",
       "  (('gasps', 'and'), ('and', 'comments'), ('comments', 'hopefully')),\n",
       "  (('and', 'comments'), ('comments', 'hopefully'), ('hopefully', 'people')),\n",
       "  (('comments', 'hopefully'), ('hopefully', 'people'), ('people', 'realize')),\n",
       "  (('hopefully', 'people'), ('people', 'realize'), ('realize', 'this')),\n",
       "  (('people', 'realize'), ('realize', 'this'), ('this', 'movie')),\n",
       "  (('realize', 'this'), ('this', 'movie'), ('movie', 'was')),\n",
       "  (('this', 'movie'), ('movie', 'was'), ('was', 'made')),\n",
       "  (('movie', 'was'), ('was', 'made'), ('made', 'for')),\n",
       "  (('was', 'made'), ('made', 'for'), ('for', 'kids')),\n",
       "  (('made', 'for'), ('for', 'kids'), ('kids', 'as')),\n",
       "  (('for', 'kids'), ('kids', 'as'), ('as', 'such')),\n",
       "  (('kids', 'as'), ('as', 'such'), ('such', 'it')),\n",
       "  (('as', 'such'), ('such', 'it'), ('it', 'was')),\n",
       "  (('such', 'it'), ('it', 'was'), ('was', 'successful')),\n",
       "  (('it', 'was'), ('was', 'successful'), ('successful', 'although')),\n",
       "  (('was', 'successful'), ('successful', 'although'), ('although', 'i')),\n",
       "  (('successful', 'although'), ('although', 'i'), ('i', 'liked')),\n",
       "  (('although', 'i'), ('i', 'liked'), ('liked', 'it')),\n",
       "  (('i', 'liked'), ('liked', 'it'), ('it', 'too')),\n",
       "  (('liked', 'it'), ('it', 'too'), ('too', 'personally')),\n",
       "  (('it', 'too'), ('too', 'personally'), ('personally', 'i')),\n",
       "  (('too', 'personally'), ('personally', 'i'), ('i', 'liked')),\n",
       "  (('personally', 'i'), ('i', 'liked'), ('liked', 'the')),\n",
       "  (('i', 'liked'), ('liked', 'the'), ('the', 'scrat'))]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_tokens[5:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max vacabulary size is 20000\n",
    "from collections import Counter\n",
    "\n",
    "max_vocab_size = 20000\n",
    "# save index 0 for unk and 1 for pad\n",
    "PAD_IDX = 0\n",
    "UNK_IDX = 1\n",
    "\n",
    "def build_vocab(all_tokens):\n",
    "    # Returns:\n",
    "    # id2token: list of tokens, where id2token[i] returns token that corresponds to token i\n",
    "    # token2id: dictionary where keys represent tokens and corresponding values represent indices\n",
    "    token_counter = Counter(all_tokens)\n",
    "    vocab, count = zip(*token_counter.most_common(max_vocab_size))\n",
    "    id2token = list(vocab)\n",
    "    token2id = dict(zip(vocab, range(2,2+len(vocab)))) \n",
    "    id2token = ['<pad>', '<unk>'] + id2token\n",
    "    token2id['<pad>'] = PAD_IDX \n",
    "    token2id['<unk>'] = UNK_IDX\n",
    "    return token2id, id2token\n",
    "\n",
    "token2id, id2token = build_vocab(all_train_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 2,\n",
       " 'a': 3,\n",
       " 'and': 4,\n",
       " 'of': 5,\n",
       " 'to': 6,\n",
       " 'is': 7,\n",
       " 'in': 8,\n",
       " 'it': 9,\n",
       " 'this': 10,\n",
       " 'i': 11,\n",
       " 'that': 12,\n",
       " 'was': 13,\n",
       " 'as': 14,\n",
       " 'for': 15,\n",
       " 'with': 16,\n",
       " 'movie': 17,\n",
       " 'but': 18,\n",
       " ('of', 'the'): 19,\n",
       " 'film': 20,\n",
       " 'on': 21,\n",
       " 'not': 22,\n",
       " 'you': 23,\n",
       " 'are': 24,\n",
       " 'his': 25,\n",
       " 'have': 26,\n",
       " 'he': 27,\n",
       " 'be': 28,\n",
       " 'one': 29,\n",
       " ('in', 'the'): 30,\n",
       " 'at': 31,\n",
       " 'all': 32,\n",
       " 'by': 33,\n",
       " 'an': 34,\n",
       " 'they': 35,\n",
       " 'from': 36,\n",
       " 'who': 37,\n",
       " 'so': 38,\n",
       " 'like': 39,\n",
       " 'her': 40,\n",
       " 'just': 41,\n",
       " 'or': 42,\n",
       " 'about': 43,\n",
       " \"it's\": 44,\n",
       " 'has': 45,\n",
       " 'out': 46,\n",
       " 'if': 47,\n",
       " 'some': 48,\n",
       " 'there': 49,\n",
       " ('this', 'movie'): 50,\n",
       " 'what': 51,\n",
       " 'good': 52,\n",
       " 'when': 53,\n",
       " 'more': 54,\n",
       " 'very': 55,\n",
       " ('and', 'the'): 56,\n",
       " ('is', 'a'): 57,\n",
       " 'even': 58,\n",
       " 'my': 59,\n",
       " ('the', 'film'): 60,\n",
       " 'she': 61,\n",
       " 'up': 62,\n",
       " 'no': 63,\n",
       " 'time': 64,\n",
       " ('to', 'the'): 65,\n",
       " 'only': 66,\n",
       " 'would': 67,\n",
       " 'which': 68,\n",
       " ('to', 'be'): 69,\n",
       " 'really': 70,\n",
       " 'story': 71,\n",
       " 'their': 72,\n",
       " ('the', 'movie'): 73,\n",
       " 'see': 74,\n",
       " 'had': 75,\n",
       " 'can': 76,\n",
       " 'were': 77,\n",
       " ('this', 'film'): 78,\n",
       " 'me': 79,\n",
       " ('it', 'is'): 80,\n",
       " 'we': 81,\n",
       " 'than': 82,\n",
       " 'much': 83,\n",
       " ('this', 'is'): 84,\n",
       " 'well': 85,\n",
       " 'been': 86,\n",
       " 'get': 87,\n",
       " 'into': 88,\n",
       " 'will': 89,\n",
       " 'also': 90,\n",
       " 'do': 91,\n",
       " 'people': 92,\n",
       " 'other': 93,\n",
       " 'bad': 94,\n",
       " 'him': 95,\n",
       " 'because': 96,\n",
       " 'great': 97,\n",
       " ('on', 'the'): 98,\n",
       " ('in', 'a'): 99,\n",
       " 'first': 100,\n",
       " 'how': 101,\n",
       " 'most': 102,\n",
       " \"don't\": 103,\n",
       " ('it', 'was'): 104,\n",
       " 'made': 105,\n",
       " ('one', 'of'): 106,\n",
       " 'its': 107,\n",
       " 'then': 108,\n",
       " ('for', 'the'): 109,\n",
       " 'them': 110,\n",
       " 'way': 111,\n",
       " ('with', 'the'): 112,\n",
       " 'make': 113,\n",
       " ('of', 'a'): 114,\n",
       " 'could': 115,\n",
       " 'any': 116,\n",
       " 'too': 117,\n",
       " 'after': 118,\n",
       " 'movies': 119,\n",
       " 'think': 120,\n",
       " ('is', 'the'): 121,\n",
       " 'characters': 122,\n",
       " ('as', 'a'): 123,\n",
       " ('at', 'the'): 124,\n",
       " 'films': 125,\n",
       " 'watch': 126,\n",
       " 'two': 127,\n",
       " 'many': 128,\n",
       " 'seen': 129,\n",
       " 'being': 130,\n",
       " 'character': 131,\n",
       " 'never': 132,\n",
       " 'best': 133,\n",
       " 'acting': 134,\n",
       " 'little': 135,\n",
       " 'plot': 136,\n",
       " 'where': 137,\n",
       " 'life': 138,\n",
       " 'love': 139,\n",
       " 'did': 140,\n",
       " ('from', 'the'): 141,\n",
       " ('in', 'this'): 142,\n",
       " 'know': 143,\n",
       " 'show': 144,\n",
       " ('with', 'a'): 145,\n",
       " 'does': 146,\n",
       " ('as', 'the'): 147,\n",
       " 'ever': 148,\n",
       " 'better': 149,\n",
       " 'your': 150,\n",
       " ('if', 'you'): 151}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(list(token2id.items())[0:150])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token id 18467 ; token ('it', 'makes', 'me')\n",
      "Token ('it', 'makes', 'me'); token id 18467\n"
     ]
    }
   ],
   "source": [
    "# Lets check the dictionary by loading random token from it\n",
    "\n",
    "random_token_id = random.randint(0, len(id2token)-1)\n",
    "random_token = id2token[random_token_id]\n",
    "\n",
    "print (\"Token id {} ; token {}\".format(random_token_id, id2token[random_token_id]))\n",
    "print (\"Token {}; token id {}\".format(random_token, token2id[random_token]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Test dataset size is 25000\n"
     ]
    }
   ],
   "source": [
    "# convert token to id in the dataset\n",
    "def token2index_dataset(tokens_data):\n",
    "    indices_data = []\n",
    "    for tokens in tokens_data:\n",
    "        index_list = [token2id[token] if token in token2id else UNK_IDX for token in tokens]\n",
    "        indices_data.append(index_list)\n",
    "    return indices_data\n",
    "\n",
    "train_data_indices = token2index_dataset(train_data_tokens)\n",
    "val_data_indices = token2index_dataset(val_data_tokens)\n",
    "test_data_indices = token2index_dataset(test_data_tokens)\n",
    "\n",
    "# double checking\n",
    "print (\"Train dataset size is {}\".format(len(train_data_indices)))\n",
    "print (\"Val dataset size is {}\".format(len(val_data_indices)))\n",
    "print (\"Test dataset size is {}\".format(len(test_data_indices)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SENTENCE_LENGTH = 400\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class NewsGroupDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Class that represents a train/validation/test dataset that's readable for PyTorch\n",
    "    Note that this class inherits torch.utils.data.Dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data_list, target_list):\n",
    "        \"\"\"\n",
    "        @param data_list: list of newsgroup tokens \n",
    "        @param target_list: list of newsgroup targets \n",
    "\n",
    "        \"\"\"\n",
    "        self.data_list = data_list\n",
    "        self.target_list = target_list\n",
    "        assert (len(self.data_list) == len(self.target_list))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "        \n",
    "    def __getitem__(self, key):\n",
    "        \"\"\"\n",
    "        Triggered when you call dataset[i]\n",
    "        \"\"\"\n",
    "        \n",
    "        token_idx = self.data_list[key][:MAX_SENTENCE_LENGTH]\n",
    "        label = self.target_list[key]\n",
    "        return [token_idx, len(token_idx), label]\n",
    "\n",
    "def newsgroup_collate_func(batch):\n",
    "    \"\"\"\n",
    "    Customized function for DataLoader that dynamically pads the batch so that all \n",
    "    data have the same length\n",
    "    \"\"\"\n",
    "    data_list = []\n",
    "    label_list = []\n",
    "    length_list = []\n",
    "    #print(\"collate batch: \", batch[0][0])\n",
    "    #batch[0][0] = batch[0][0][:MAX_SENTENCE_LENGTH]\n",
    "    for datum in batch:\n",
    "        label_list.append(datum[2])\n",
    "        length_list.append(datum[1])\n",
    "    # padding\n",
    "    for datum in batch:\n",
    "        padded_vec = np.pad(np.array(datum[0]), \n",
    "                                pad_width=((0,MAX_SENTENCE_LENGTH-datum[1])), \n",
    "                                mode=\"constant\", constant_values=0)\n",
    "        data_list.append(padded_vec)\n",
    "    return [torch.from_numpy(np.array(data_list)), torch.LongTensor(length_list), torch.LongTensor(label_list)]\n",
    "\n",
    "# create pytorch dataloader\n",
    "#train_loader = NewsGroupDataset(train_data_indices, train_target)\n",
    "#val_loader = NewsGroupDataset(val_data_indices, val_target)\n",
    "#test_loader = NewsGroupDataset(test_data_indices, test_target)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "train_dataset = NewsGroupDataset(train_data_indices, train_target)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=newsgroup_collate_func,\n",
    "                                           shuffle=True)\n",
    "\n",
    "val_dataset = NewsGroupDataset(val_data_indices, val_target)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=newsgroup_collate_func,\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_dataset = NewsGroupDataset(test_data_indices, test_target)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=newsgroup_collate_func,\n",
    "                                           shuffle=False)\n",
    "\n",
    "#for i, (data, lengths, labels) in enumerate(train_loader):\n",
    "#    print (data)\n",
    "#    print (labels)\n",
    "#    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First import torch related libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BagOfWords(nn.Module):\n",
    "    \"\"\"\n",
    "    BagOfWords classification model\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, emb_dim):\n",
    "        \"\"\"\n",
    "        @param vocab_size: size of the vocabulary. \n",
    "        @param emb_dim: size of the word embedding\n",
    "        \"\"\"\n",
    "        super(BagOfWords, self).__init__()\n",
    "        # pay attention to padding_idx \n",
    "        self.embed = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n",
    "        self.linear = nn.Linear(emb_dim,20)\n",
    "    \n",
    "    def forward(self, data, length):\n",
    "        \"\"\"\n",
    "        \n",
    "        @param data: matrix of size (batch_size, max_sentence_length). Each row in data represents a \n",
    "            review that is represented using n-gram index. Note that they are padded to have same length.\n",
    "        @param length: an int tensor of size (batch_size), which represents the non-trivial (excludes padding)\n",
    "            length of each sentences in the data.\n",
    "        \"\"\"\n",
    "        out = self.embed(data)\n",
    "        out = torch.sum(out, dim=1)\n",
    "        out /= length.view(length.size()[0],1).expand_as(out).float()\n",
    "     \n",
    "        # return logits\n",
    "        out = self.linear(out.float())\n",
    "        return out\n",
    "\n",
    "emb_dim = 200\n",
    "model = BagOfWords(len(id2token), emb_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/10], Step: [101/625], Validation Acc: 51.14\n",
      "Epoch: [1/10], Step: [201/625], Validation Acc: 51.1\n",
      "Epoch: [1/10], Step: [301/625], Validation Acc: 51.86\n",
      "Epoch: [1/10], Step: [401/625], Validation Acc: 54.54\n",
      "Epoch: [1/10], Step: [501/625], Validation Acc: 55.44\n",
      "Epoch: [1/10], Step: [601/625], Validation Acc: 53.92\n",
      "Epoch: [2/10], Step: [101/625], Validation Acc: 51.28\n",
      "Epoch: [2/10], Step: [201/625], Validation Acc: 59.16\n",
      "Epoch: [2/10], Step: [301/625], Validation Acc: 52.14\n",
      "Epoch: [2/10], Step: [401/625], Validation Acc: 51.16\n",
      "Epoch: [2/10], Step: [501/625], Validation Acc: 53.88\n",
      "Epoch: [2/10], Step: [601/625], Validation Acc: 60.52\n",
      "Epoch: [3/10], Step: [101/625], Validation Acc: 62.52\n",
      "Epoch: [3/10], Step: [201/625], Validation Acc: 62.32\n",
      "Epoch: [3/10], Step: [301/625], Validation Acc: 60.92\n",
      "Epoch: [3/10], Step: [401/625], Validation Acc: 55.4\n",
      "Epoch: [3/10], Step: [501/625], Validation Acc: 54.86\n",
      "Epoch: [3/10], Step: [601/625], Validation Acc: 62.24\n",
      "Epoch: [4/10], Step: [101/625], Validation Acc: 59.94\n",
      "Epoch: [4/10], Step: [201/625], Validation Acc: 58.02\n",
      "Epoch: [4/10], Step: [301/625], Validation Acc: 60.22\n",
      "Epoch: [4/10], Step: [401/625], Validation Acc: 61.1\n",
      "Epoch: [4/10], Step: [501/625], Validation Acc: 63.54\n",
      "Epoch: [4/10], Step: [601/625], Validation Acc: 62.66\n",
      "Epoch: [5/10], Step: [101/625], Validation Acc: 58.74\n",
      "Epoch: [5/10], Step: [201/625], Validation Acc: 59.5\n",
      "Epoch: [5/10], Step: [301/625], Validation Acc: 61.06\n",
      "Epoch: [5/10], Step: [401/625], Validation Acc: 55.86\n",
      "Epoch: [5/10], Step: [501/625], Validation Acc: 61.38\n",
      "Epoch: [5/10], Step: [601/625], Validation Acc: 62.88\n",
      "Epoch: [6/10], Step: [101/625], Validation Acc: 64.22\n",
      "Epoch: [6/10], Step: [201/625], Validation Acc: 62.74\n",
      "Epoch: [6/10], Step: [301/625], Validation Acc: 64.28\n",
      "Epoch: [6/10], Step: [401/625], Validation Acc: 60.3\n",
      "Epoch: [6/10], Step: [501/625], Validation Acc: 58.34\n",
      "Epoch: [6/10], Step: [601/625], Validation Acc: 56.34\n",
      "Epoch: [7/10], Step: [101/625], Validation Acc: 58.16\n",
      "Epoch: [7/10], Step: [201/625], Validation Acc: 57.7\n",
      "Epoch: [7/10], Step: [301/625], Validation Acc: 64.6\n",
      "Epoch: [7/10], Step: [401/625], Validation Acc: 61.9\n",
      "Epoch: [7/10], Step: [501/625], Validation Acc: 58.46\n",
      "Epoch: [7/10], Step: [601/625], Validation Acc: 58.48\n",
      "Epoch: [8/10], Step: [101/625], Validation Acc: 61.5\n",
      "Epoch: [8/10], Step: [201/625], Validation Acc: 64.44\n",
      "Epoch: [8/10], Step: [301/625], Validation Acc: 63.04\n",
      "Epoch: [8/10], Step: [401/625], Validation Acc: 64.64\n",
      "Epoch: [8/10], Step: [501/625], Validation Acc: 65.06\n",
      "Epoch: [8/10], Step: [601/625], Validation Acc: 64.74\n",
      "Epoch: [9/10], Step: [101/625], Validation Acc: 65.02\n",
      "Epoch: [9/10], Step: [201/625], Validation Acc: 61.24\n",
      "Epoch: [9/10], Step: [301/625], Validation Acc: 65.1\n",
      "Epoch: [9/10], Step: [401/625], Validation Acc: 62.44\n",
      "Epoch: [9/10], Step: [501/625], Validation Acc: 59.22\n",
      "Epoch: [9/10], Step: [601/625], Validation Acc: 65.26\n",
      "Epoch: [10/10], Step: [101/625], Validation Acc: 60.36\n",
      "Epoch: [10/10], Step: [201/625], Validation Acc: 65.34\n",
      "Epoch: [10/10], Step: [301/625], Validation Acc: 65.64\n",
      "Epoch: [10/10], Step: [401/625], Validation Acc: 65.0\n",
      "Epoch: [10/10], Step: [501/625], Validation Acc: 63.28\n",
      "Epoch: [10/10], Step: [601/625], Validation Acc: 65.52\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "num_epochs = 10 # number epoch to train\n",
    "\n",
    "# Criterion and Optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()  \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Function for testing the model\n",
    "def test_model(loader, model):\n",
    "    \"\"\"\n",
    "    Help function that tests the model's performance on a dataset\n",
    "    @param: loader - data loader for the dataset to test against\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    for data, lengths, labels in loader:\n",
    "        data_batch, length_batch, label_batch = data, lengths, labels\n",
    "        outputs = F.softmax(model(data_batch, length_batch), dim=1)\n",
    "        predicted = outputs.max(1, keepdim=True)[1]\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels.view_as(predicted)).sum().item()\n",
    "    return (100 * correct / total)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (data, lengths, labels) in enumerate(train_loader):\n",
    "        model.train()\n",
    "        data_batch, length_batch, label_batch = data, lengths, labels\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data_batch, length_batch)\n",
    "        loss = criterion(outputs, label_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # validate every 100 iterations\n",
    "        if i > 0 and i % 100 == 0:\n",
    "            # validate\n",
    "            val_acc = test_model(val_loader, model)\n",
    "            print('Epoch: [{}/{}], Step: [{}/{}], Validation Acc: {}'.format( \n",
    "                       epoch+1, num_epochs, i+1, len(train_loader), val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training for 10 epochs\n",
      "Val Acc 59.06\n",
      "Test Acc 58.872\n"
     ]
    }
   ],
   "source": [
    "print (\"After training for {} epochs\".format(num_epochs))\n",
    "print (\"Val Acc {}\".format(test_model(val_loader, model)))\n",
    "print (\"Test Acc {}\".format(test_model(test_loader, model)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
